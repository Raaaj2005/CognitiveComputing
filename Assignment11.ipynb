{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68777496-a69f-4cfc-86b4-de72541e39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import pyttsx3\n",
    "\n",
    "def read_medicine_label(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    processed = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    text = pytesseract.image_to_string(processed)\n",
    "    return text\n",
    "\n",
    "def speak_text(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 150)\n",
    "    engine.say(\"Here is what I found on the medicine label.\")\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    img_path = \"medicine_label.jpg\" \n",
    "    label_text = read_medicine_label(img_path)\n",
    "    print(\"Detected Text:\\n\", label_text)\n",
    "    speak_text(label_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d860bb0-88ee-4ebc-b2ac-202b6877294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from fer import FER\n",
    "import pyttsx3\n",
    "\n",
    "def speak_emotion_response(emotion):\n",
    "    responses = {\n",
    "        \"happy\": \"You look happy! Keep smiling!\",\n",
    "        \"sad\": \"You seem sad. I'm here if you want to talk.\",\n",
    "        \"angry\": \"You look angry. Maybe take a deep breath?\",\n",
    "        \"surprise\": \"That's a surprising look! What's going on?\",\n",
    "        \"neutral\": \"You look calm and neutral.\",\n",
    "        \"fear\": \"You seem a bit fearful. Everything okay?\",\n",
    "        \"disgust\": \"You look disgusted. Is something wrong?\"\n",
    "    }\n",
    "    response = responses.get(emotion, \"I'm not sure how you're feeling.\")\n",
    "    print(\"Assistant:\", response)\n",
    "    \n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(response)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def detect_emotion():\n",
    "    detector = FER(mtcnn=True)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    print(\"Press 'q' to quit...\")\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        result = detector.detect_emotions(frame)\n",
    "        if result:\n",
    "            top_emotion = max(result[0][\"emotions\"], key=result[0][\"emotions\"].get)\n",
    "            cv2.putText(frame, f\"Emotion: {top_emotion}\", (30, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            speak_emotion_response(top_emotion)\n",
    "        \n",
    "        cv2.imshow(\"Emotion Detection\", frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    detect_emotion()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
