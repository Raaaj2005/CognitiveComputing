{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6debb24-658c-4474-ba1d-0df919ad7258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "paragraph = \"\"\"\n",
    "Books have always been a source of inspiration and knowledge for me. \n",
    "Reading fiction allows me to explore new worlds, while non-fiction helps me understand real-life complexities. \n",
    "The smell of old pages, the feel of a hardcover, and the quiet moments spent reading are priceless. \n",
    "Books challenge my thinking and broaden my perspective on diverse subjects. \n",
    "Whether it's a thrilling mystery or a profound biography, reading enriches my soul and sharpens my mind.\n",
    "\"\"\"\n",
    "lowercase_text = paragraph.lower()\n",
    "no_punctuation_text = lowercase_text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "sentences = sent_tokenize(paragraph)\n",
    "words = word_tokenize(no_punctuation_text)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "freq_dist = FreqDist(filtered_words)\n",
    "plt.figure(figsize=(10, 5))\n",
    "freq_dist.plot(20, title=\"Top 20 Word Frequencies (excluding stopwords)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339556e-785f-476e-8b7f-695b9435ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "paragraph = \"\"\"\n",
    "Books have always been a source of inspiration and knowledge for me. \n",
    "Reading fiction allows me to explore new worlds, while non-fiction helps me understand real-life complexities. \n",
    "The smell of old pages, the feel of a hardcover, and the quiet moments spent reading are priceless. \n",
    "Books challenge my thinking and broaden my perspective on diverse subjects. \n",
    "Whether it's a thrilling mystery or a profound biography, reading enriches my soul and sharpens my mind.\n",
    "\"\"\"\n",
    "\n",
    "lowercase_text = paragraph.lower()\n",
    "clean_text = lowercase_text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "words = word_tokenize(clean_text)\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "porter_stems = [porter.stem(word) for word in filtered_words]\n",
    "lancaster_stems = [lancaster.stem(word) for word in filtered_words]\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "\n",
    "print(f\"{'Original':<15} {'Porter':<15} {'Lancaster':<15} {'Lemmatized':<15}\")\n",
    "print(\"=\" * 60)\n",
    "for original, p_stem, l_stem, lemma in zip(filtered_words, porter_stems, lancaster_stems, lemmatized_words):\n",
    "    print(f\"{original:<15} {p_stem:<15} {l_stem:<15} {lemma:<15}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd320a5c-70c5-42db-becc-164240f4d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "import re\n",
    "\n",
    "paragraph = \"\"\"\n",
    "Books have always been a source of inspiration and knowledge for me. \n",
    "Reading fiction allows me to explore new worlds, while non-fiction helps me understand real-life complexities. \n",
    "The smell of old pages, the feel of a hardcover, and the quiet moments spent reading are priceless. \n",
    "Books challenge my thinking and broaden my perspective on diverse subjects. \n",
    "Whether it's a thrilling mystery or a profound biography, reading enriches my soul and sharpens my mind.\n",
    "\"\"\"\n",
    "\n",
    "# a. Extract all words with more than 5 letters\n",
    "words_more_than_5 = re.findall(r'\\b[a-zA-Z]{6,}\\b', paragraph)\n",
    "\n",
    "# b. Extract all numbers\n",
    "numbers = re.findall(r'\\b\\d+\\b', paragraph)\n",
    "\n",
    "# c. Extract all capitalized words\n",
    "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', paragraph)\n",
    "\n",
    "# d. Split text into alphabet-only words\n",
    "alphabet_words = re.findall(r'\\b[a-zA-Z]+\\b', paragraph)\n",
    "\n",
    "# e. Extract words starting with a vowel (case insensitive)\n",
    "vowel_words = [word for word in alphabet_words if re.match(r'^[aeiouAEIOU]', word)]\n",
    "\n",
    "print(\"Words with more than 5 letters:\", words_more_than_5)\n",
    "print(\"Numbers:\", numbers)\n",
    "print(\"Capitalized words:\", capitalized_words)\n",
    "print(\"Alphabet-only words:\", alphabet_words)\n",
    "print(\"Words starting with a vowel:\", vowel_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f729a-073f-4ea3-9d7a-fa46d59a5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4\n",
    "import re\n",
    "\n",
    "paragraph = \"\"\"\n",
    "Books have always been a source of inspiration and knowledge for me. \n",
    "Reading fiction allows me to explore new worlds, while non-fiction helps me understand real-life complexities. \n",
    "The smell of old pages, the feel of a hardcover, and the quiet moments spent reading are priceless. \n",
    "Books challenge my thinking and broaden my perspective on diverse subjects. \n",
    "Whether it's a thrilling mystery or a profound biography, reading enriches my soul and sharpens my mind.\n",
    "Contact me at example.email@domain.com or visit https://www.booklover.com.\n",
    "You can also call me at +91 9876543210 or 123-456-7890.\n",
    "\"\"\"\n",
    "\n",
    "text = re.sub(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', '<EMAIL>', paragraph)\n",
    "text = re.sub(r'https?://[^\\s]+', '<URL>', text)\n",
    "text = re.sub(r'(\\+?\\d{1,3})?\\s?\\d{10}|\\d{3}-\\d{3}-\\d{4}', '<PHONE>', text)\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    pattern = r\"\\b(?:\\d+\\.\\d+|\\w+(?:-\\w+)*|'[a-z]+|\\w+)\\b\"\n",
    "    return re.findall(pattern, text, re.IGNORECASE)\n",
    "\n",
    "tokens = custom_tokenizer(text)\n",
    "\n",
    "print(\"Processed Text:\")\n",
    "print(text)\n",
    "print(\"\\nCustom Tokens:\")\n",
    "print(tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
